{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60863aeb-06ac-416f-97d7-f0f3004e6272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SophieFlentge\\Downloads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SophieFlentge\\AppData\\Local\\Temp\\ipykernel_17776\\2768854969.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  simplebas_subset['Source'] = 'Simple'\n",
      "C:\\Users\\SophieFlentge\\AppData\\Local\\Temp\\ipykernel_17776\\2768854969.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fullbas_subset['Source'] = 'Full'\n",
      "C:\\Users\\SophieFlentge\\AppData\\Local\\Temp\\ipykernel_17776\\2768854969.py:68: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  combined_bas['datetime'] = pd.to_datetime(combined_bas['datetime'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productoption\n",
      "Premium 5                           49333\n",
      "Standard                            45278\n",
      "Premium 20                          37625\n",
      "Premium                             37318\n",
      "Premium 50                          21804\n",
      "Premium 100                         10349\n",
      "GST Cashbook                         7333\n",
      "Starter                              4975\n",
      "Premium 20 + Expenses                1709\n",
      "Premium 5 + Expenses                 1518\n",
      "Premium 5 + Projects                 1300\n",
      "Payroll Cashbook                     1283\n",
      "Premium 50 + Expenses                1197\n",
      "Ledger                               1190\n",
      "Standard + Expenses                  1028\n",
      "Standard + Projects                   519\n",
      "Premium 20 + Projects                 467\n",
      "Premium 100 + Projects                444\n",
      "Premium + Expenses                    437\n",
      "Premium 100 + Expenses                422\n",
      "Premium 5 + Projects + Expenses       269\n",
      "Non-GST Cashbook                      252\n",
      "Premium + Projects + Expenses         221\n",
      "Premium 50 + Projects + Expenses      187\n",
      "Payroll only                           36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TAKE HOME TEST FOR DATA SCIENCE ROLE\n",
    "\n",
    "**Dependencies**\n",
    "Python libraries requires to run script\n",
    "    `pandas` \n",
    "\n",
    "**Set up**\n",
    "Please make sure the following files are located in your working directory before running script\n",
    "    `fullbas.csv`\n",
    "    `simplebas.csv`\n",
    "    `orgcard.csv`\n",
    "\"\"\"\n",
    "### SET UP\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Use this section to navigate to appropriate directory - it is assumed that CSV data is in your Downloads folder\n",
    "os.chdir(\"Downloads\")  \n",
    "print(os.getcwd())  \n",
    "\n",
    "### IMPORT DATA\n",
    "full_bas = pd.read_csv(\"fullbas.csv\")\n",
    "simple_bas = pd.read_csv(\"simplebas.csv\")\n",
    "org_card = pd.read_csv(\"orgcard.csv\")\n",
    "\n",
    "### SEE DATA QUALITIES\n",
    "# Check out var names and data format\n",
    "#full_bas.head()\n",
    "#simple_bas.head()\n",
    "#org_card.head()\n",
    "\n",
    "### FIRST OBSERVATIONS\n",
    "# Both full and simple BAS look to be one record per report run, though the format is definitely different\n",
    "# User ID & Org ID look like they are in the same format so should match up.\n",
    "# Dates are in different Formats so will need to convert. Min and Max dates of each data set overlap showing transitionary change over\n",
    "# Am assuming dates are both in UTC\n",
    "# Full BAS report name is a label while Simple BAS report identifier is a code (for now I will need to assume that somewhere has info to convert report code to appropriate label)\n",
    "# PROBLEM: Simple BAS has no OrgID so cannot be joined to ORGCARD - do we have a users table (with orgID) we could use as an intermediary join?? - This means we can't filter to only active and paying orgs for both full and simple.\n",
    "\n",
    "min_fullbas_date = full_bas['datestring'].min()\n",
    "max_fullbas_date = full_bas['datestring'].max()\n",
    "min_simbas_date = simple_bas['datetime'].min()\n",
    "max_simbas_date = simple_bas['datetime'].max()\n",
    "\n",
    "# There is only one level to Report Name in Full BAS but 963 in simple - this seems unusual, though there are different versions. The questions dont ask to breakdown by report so I will assume it's fine to accept this structure\n",
    "distinct_fullbas_reports = full_bas['reportname'].nunique()\n",
    "distinct_simbas_reports = simple_bas['shortcode'].nunique()\n",
    "\n",
    "### MAKING A SINGLE EASY TO USE DATASET\n",
    "# Data is conceptually the same, but formatted differently so in order to be able to work with simple BAS and full BAS as a whole they'll need to be added together\n",
    "full_bas['datetime'] = pd.to_datetime(full_bas['datestring'] + ' ' + full_bas['timestring'])\n",
    "\n",
    "\n",
    "# Bring only user ID and Timestamp (as that's all that's needed to answer questions - with the exception of orgid but we can't join that to simple bas)\n",
    "simplebas_subset = simple_bas[['userid', 'datetime']]\n",
    "fullbas_subset = full_bas[['userid', 'datetime']]\n",
    "\n",
    "# Create source field to identify which table the run comes from\n",
    "simplebas_subset['Source'] = 'Simple'\n",
    "fullbas_subset['Source'] = 'Full'\n",
    "\n",
    "# Stach the two source datasets to one workable dataset\n",
    "combined_bas = pd.concat([simplebas_subset, fullbas_subset], ignore_index=True)\n",
    "\n",
    "### LOOKING FOR PATTERNS & TRENDS\n",
    "# Make Datetime all the same format (was different for each source)\n",
    "combined_bas['datetime'] = pd.to_datetime(combined_bas['datetime'])\n",
    "# Check no null values in Dates as I was having trouple aggregating by month to start with\n",
    "#print(combined_bas['datetime'].isnull().sum())\n",
    "\n",
    "# Was getting an error about mized time zones - am assuming both UTC, but in real life may been to be converted to UTC first\n",
    "combined_bas['datetime'] = pd.to_datetime(combined_bas['datetime'], utc=True)\n",
    "\n",
    "# Create a month column & Aggregate for answer to Q1\n",
    "combined_bas['month_year'] = combined_bas['datetime'].dt.strftime('%Y-%m')\n",
    "monthly_count = combined_bas.groupby('month_year').size().reset_index(name='row_count')\n",
    "\n",
    "simple_bas_users = simple_bas['userid'].unique()\n",
    "full_bas_users = full_bas['userid'].unique()\n",
    "common_users = set(simple_bas_users) & set(full_bas_users)\n",
    "num_common_users = len(common_users)\n",
    "\n",
    "### answers to questions\n",
    "# ● What month saw the most report runs? - 2018-08 with 12598 (this is not limited to active and paying orgs as per orgcard/simple bas join issue with data)\n",
    "# ● How many orgs ran both of the reports? - we can't find this unless we find a way to join orgcard to simplebas (perhaps check if a user table exists?). If we had this we would do something similiar to the SQL secion one problem.\n",
    "# ● How many users have used either of the reports? - 1470 users are present in both simple and full bas reports\n",
    "\n",
    "### The following shouldn't really be done without having org card joined to simple_bas, though for the sake of answering the questions I am now only looking at full BAS (and active/paying orgs as this info is now available to all orgs)\n",
    "# ● How many users have run reports for multiple organisations? - 277 users have run full BAS only reports for multiple orgs\n",
    "# ● Which pricing plans are the most popular for orgs using BAS? - Premium 5 with 49333, again this is only Full BAS\n",
    "\n",
    "paying_org_card = org_card[(org_card['organisationstatus'] == 'Active') & (org_card['payingflag'] == 1)]\n",
    "\n",
    "# # Org card ID is uppercase while full bas is upper & lower (This is an actual problem with some XERO data)\n",
    "full_bas['orgid'] = full_bas['orgid'].str.upper()\n",
    "full_bas_paying = pd.merge(full_bas, paying_org_card, left_on='orgid', right_on='organisationid', how='inner')\n",
    "\n",
    "users_multiple_orgs = full_bas_paying.groupby('userid')['orgid'].nunique()\n",
    "users_multiple_orgs = users_multiple_orgs[users_multiple_orgs > 1]\n",
    "#print(users_multiple_orgs.count())\n",
    "\n",
    "pricing_plan_counts = full_bas_paying['productoption'].value_counts()\n",
    "print(pricing_plan_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
